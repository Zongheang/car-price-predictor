{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "385c002f",
   "metadata": {},
   "source": [
    "1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "726ecd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded raw data from data\\raw\\quikr_car.csv\n",
      "Shape: (892, 6)\n",
      "First 10 rows:\n",
      "                                     name   company  year          Price  \\\n",
      "0    Hyundai Santro Xing XO eRLX Euro III   Hyundai  2007         80,000   \n",
      "1                 Mahindra Jeep CL550 MDI  Mahindra  2006       4,25,000   \n",
      "2              Maruti Suzuki Alto 800 Vxi    Maruti  2018  Ask For Price   \n",
      "3  Hyundai Grand i10 Magna 1.2 Kappa VTVT   Hyundai  2014       3,25,000   \n",
      "4        Ford EcoSport Titanium 1.5L TDCi      Ford  2014       5,75,000   \n",
      "5        Ford EcoSport Titanium 1.5L TDCi      Ford  2015  Ask For Price   \n",
      "6                               Ford Figo      Ford  2012       1,75,000   \n",
      "7                             Hyundai Eon   Hyundai  2013       1,90,000   \n",
      "8        Ford EcoSport Ambiente 1.5L TDCi      Ford  2016       8,30,000   \n",
      "9          Maruti Suzuki Alto K10 VXi AMT    Maruti  2015       2,50,000   \n",
      "\n",
      "   kms_driven fuel_type  \n",
      "0  45,000 kms    Petrol  \n",
      "1      40 kms    Diesel  \n",
      "2  22,000 kms    Petrol  \n",
      "3  28,000 kms    Petrol  \n",
      "4  36,000 kms    Diesel  \n",
      "5  59,000 kms    Diesel  \n",
      "6  41,000 kms    Diesel  \n",
      "7  25,000 kms    Petrol  \n",
      "8  24,530 kms    Diesel  \n",
      "9  60,000 kms    Petrol  \n",
      "\n",
      "Dataset shape: (892, 6)\n",
      "\n",
      "Data types and missing values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 892 entries, 0 to 891\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   name        892 non-null    object\n",
      " 1   company     892 non-null    object\n",
      " 2   year        892 non-null    object\n",
      " 3   Price       892 non-null    object\n",
      " 4   kms_driven  840 non-null    object\n",
      " 5   fuel_type   837 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 41.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths using your project structure\n",
    "DATA_DIR = Path(\"data\")\n",
    "RAW_DATA_PATH = DATA_DIR / \"raw/quikr_car.csv\"\n",
    "\n",
    "\n",
    "# 1. Load raw data with error handling\n",
    "try:\n",
    "    car = pd.read_csv(RAW_DATA_PATH)\n",
    "    print(f\"✅ Successfully loaded raw data from {RAW_DATA_PATH}\")\n",
    "    print(f\"Shape: {car.shape}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: File not found at {RAW_DATA_PATH}\")\n",
    "    print(\"Please verify:\")\n",
    "    print(f\"- The 'data/raw' directory exists\")\n",
    "    print(f\"- The 'quikr_car.csv' file exists in that directory\")\n",
    "    raise\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading CSV file: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# Initial exploration\n",
    "print(\"First 10 rows:\")\n",
    "print(car.head(10))\n",
    "print(\"\\nDataset shape:\", car.shape)\n",
    "print(\"\\nData types and missing values:\")\n",
    "print(car.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6afd75a",
   "metadata": {},
   "source": [
    "2. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c9cd741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully saved cleaned data to data\\processed\\Cleaned_Car_data.csv\n",
      "File size: 40.80 KB\n",
      "\n",
      "Cleaned dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 815 entries, 0 to 814\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   name        815 non-null    object\n",
      " 1   company     815 non-null    object\n",
      " 2   year        815 non-null    int64 \n",
      " 3   Price       815 non-null    int64 \n",
      " 4   kms_driven  815 non-null    int64 \n",
      " 5   fuel_type   815 non-null    object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 38.3+ KB\n",
      "None\n",
      "\n",
      "Descriptive statistics:\n",
      "                       name company         year         Price     kms_driven  \\\n",
      "count                   815     815   815.000000  8.150000e+02     815.000000   \n",
      "unique                  254      25          NaN           NaN            NaN   \n",
      "top     Maruti Suzuki Swift  Maruti          NaN           NaN            NaN   \n",
      "freq                     51     221          NaN           NaN            NaN   \n",
      "mean                    NaN     NaN  2012.442945  4.017933e+05   46277.096933   \n",
      "std                     NaN     NaN     4.005079  3.815888e+05   34318.459638   \n",
      "min                     NaN     NaN  1995.000000  3.000000e+04       0.000000   \n",
      "25%                     NaN     NaN  2010.000000  1.750000e+05   27000.000000   \n",
      "50%                     NaN     NaN  2013.000000  2.999990e+05   41000.000000   \n",
      "75%                     NaN     NaN  2015.000000  4.900000e+05   56879.000000   \n",
      "max                     NaN     NaN  2019.000000  3.100000e+06  400000.000000   \n",
      "\n",
      "       fuel_type  \n",
      "count        815  \n",
      "unique         3  \n",
      "top       Petrol  \n",
      "freq         428  \n",
      "mean         NaN  \n",
      "std          NaN  \n",
      "min          NaN  \n",
      "25%          NaN  \n",
      "50%          NaN  \n",
      "75%          NaN  \n",
      "max          NaN  \n"
     ]
    }
   ],
   "source": [
    "# Create backup\n",
    "backup = car.copy()\n",
    "\n",
    "# Clean year column\n",
    "car = car[car['year'].str.isnumeric()]\n",
    "car['year'] = car['year'].astype(int)\n",
    "\n",
    "# Clean price column\n",
    "car = car[car['Price'] != 'Ask For Price']\n",
    "car['Price'] = car['Price'].str.replace(',', '').astype(int)\n",
    "\n",
    "# Clean kms_driven column\n",
    "car['kms_driven'] = car['kms_driven'].str.split().str.get(0).str.replace(',', '')\n",
    "car = car[car['kms_driven'].str.isnumeric()]\n",
    "car['kms_driven'] = car['kms_driven'].astype(int)\n",
    "\n",
    "# Handle missing values in fuel_type\n",
    "car = car[~car['fuel_type'].isna()]\n",
    "\n",
    "# Simplify car names\n",
    "car['name'] = car['name'].str.split().str.slice(start=0, stop=3).str.join(' ')\n",
    "\n",
    "# Remove outliers\n",
    "car = car[car['Price'] < 6000000]\n",
    "\n",
    "# Reset index\n",
    "car = car.reset_index(drop=True)\n",
    "\n",
    "# Save cleaned data\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "CLEANED_DATA_PATH = PROCESSED_DIR / \"Cleaned_Car_data.csv\"\n",
    "# Ensure the processed directory exists\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "# Save the cleaned data with error handling\n",
    "try:\n",
    "    car.to_csv(CLEANED_DATA_PATH, index=False)\n",
    "    print(f\"✅ Successfully saved cleaned data to {CLEANED_DATA_PATH}\")\n",
    "    print(f\"File size: {os.path.getsize(CLEANED_DATA_PATH)/1024:.2f} KB\")\n",
    "    \n",
    "except PermissionError:\n",
    "    print(f\"❌ Permission denied: Could not save to {CLEANED_DATA_PATH}\")\n",
    "    print(\"Please check your write permissions for this location\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error saving cleaned data: {str(e)}\")\n",
    "    print(\"Please verify:\")\n",
    "    print(f\"- The directory {PROCESSED_DIR} exists\")\n",
    "    print(f\"- You have sufficient disk space\")\n",
    "\n",
    "\n",
    "# Final dataset info\n",
    "print(\"\\nCleaned dataset info:\")\n",
    "print(car.info())\n",
    "print(\"\\nDescriptive statistics:\")\n",
    "print(car.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea767cd",
   "metadata": {},
   "source": [
    "3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "589d80cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songhieng.oeng\\AppData\\Local\\Temp\\ipykernel_24012\\2363558584.py:7: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha='right')\n",
      "C:\\Users\\songhieng.oeng\\AppData\\Local\\Temp\\ipykernel_24012\\2363558584.py:16: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha='right')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set style for plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Price distribution by company\n",
    "plt.figure(figsize=(15, 7))\n",
    "ax = sns.boxplot(x='company', y='Price', data=car)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha='right')\n",
    "plt.title('Price Distribution by Company')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/price_by_company.png')\n",
    "plt.close()\n",
    "\n",
    "# Price vs Year\n",
    "plt.figure(figsize=(20, 10))\n",
    "ax = sns.swarmplot(x='year', y='Price', data=car, size=3)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha='right')\n",
    "plt.title('Price vs Manufacturing Year')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/price_vs_year.png')\n",
    "plt.close()\n",
    "\n",
    "# Price vs Kilometers Driven\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.relplot(x='kms_driven', y='Price', data=car, height=6, aspect=1.5)\n",
    "plt.title('Price vs Kilometers Driven')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/price_vs_kms.png')\n",
    "plt.close()\n",
    "\n",
    "# Price distribution by fuel type\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.boxplot(x='fuel_type', y='Price', data=car)\n",
    "plt.title('Price Distribution by Fuel Type')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/price_by_fuel_type.png')\n",
    "plt.close()\n",
    "\n",
    "# Multivariate analysis\n",
    "plt.figure(figsize=(15, 8))\n",
    "ax = sns.relplot(x='company', y='Price', data=car, hue='fuel_type', size='year', \n",
    "                height=7, aspect=2, sizes=(40, 200), alpha=0.7)\n",
    "ax.set_xticklabels(rotation=40, ha='right')\n",
    "plt.title('Price by Company, Fuel Type, and Year')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/multivariate_analysis.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21df94ac",
   "metadata": {},
   "source": [
    "4. Feature Engineering and Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ff5567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = car[['name', 'company', 'year', 'kms_driven', 'fuel_type']]\n",
    "y = car['Price']\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X[['name', 'company', 'fuel_type']])\n",
    "\n",
    "# Create column transformer\n",
    "column_trans = make_column_transformer(\n",
    "    (OneHotEncoder(categories=ohe.categories_), ['name', 'company', 'fuel_type']),\n",
    "    remainder='passthrough',\n",
    "    force_int_remainder_cols=False\n",
    ")\n",
    "\n",
    "# Create pipeline\n",
    "lr = LinearRegression()\n",
    "pipe = make_pipeline(column_trans, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde2f7d7",
   "metadata": {},
   "source": [
    "5. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9734d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best R2 score: 0.8991 at random state: 302\n",
      "\n",
      "Final Model Metrics:\n",
      "MAE: 98320.65\n",
      "MSE: 19368279318.63\n",
      "RMSE: 139169.97\n",
      "R² Score: 0.8991\n",
      "✅ Model successfully saved to models\\LinearRegressionModel.pkl\n"
     ]
    }
   ],
   "source": [
    "# Find best random state for train-test split\n",
    "best_score = -1\n",
    "best_random_state = 0\n",
    "scores = []\n",
    "\n",
    "for i in range(1000):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=i)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    current_score = r2_score(y_test, y_pred)\n",
    "    scores.append(current_score)\n",
    "    \n",
    "    if current_score > best_score:\n",
    "        best_score = current_score\n",
    "        best_random_state = i\n",
    "\n",
    "print(f\"\\nBest R2 score: {best_score:.4f} at random state: {best_random_state}\")\n",
    "\n",
    "# Train final model with best random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=best_random_state)\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nFinal Model Metrics:\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "\n",
    "# 1. Define paths (using pathlib for cross-platform compatibility)\n",
    "MODELS_DIR = Path(\"models\")\n",
    "MODEL_PATH = MODELS_DIR / \"LinearRegressionModel.pkl\"\n",
    "\n",
    "# 2. Create models directory if it doesn't exist\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# 3. Save the model safely using context manager\n",
    "try:\n",
    "    with open(MODEL_PATH, \"wb\") as f:\n",
    "        pickle.dump(pipe, f)\n",
    "    print(f\"✅ Model successfully saved to {MODEL_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to save model: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afa595c",
   "metadata": {},
   "source": [
    "6. Model Interpretation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0226f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Most Important Features:\n",
      "                          Feature     Importance\n",
      "254                  company_Audi  934605.465994\n",
      "172            name_Mini Cooper S  644333.935200\n",
      "270                  company_Mini  644333.935200\n",
      "264                company_Jaguar  547290.473510\n",
      "256             company_Chevrolet -488781.705456\n",
      "255                   company_BMW  454792.570260\n",
      "269              company_Mercedes  454511.502420\n",
      "174  name_Mitsubishi Pajero Sport  435683.732532\n",
      "275                  company_Tata -415586.932574\n",
      "271            company_Mitsubishi  384565.814932\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance Analysis\n",
    "def get_feature_importance(pipe, X_train):\n",
    "    # Get feature names after one-hot encoding\n",
    "    ohe = pipe.named_steps['columntransformer'].named_transformers_['onehotencoder']\n",
    "    feature_names = ohe.get_feature_names_out(['name', 'company', 'fuel_type'])\n",
    "    feature_names = np.append(feature_names, ['year', 'kms_driven'])\n",
    "    \n",
    "    # Get coefficients\n",
    "    coefficients = pipe.named_steps['linearregression'].coef_\n",
    "    \n",
    "    # Create DataFrame for visualization\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': coefficients\n",
    "    }).sort_values('Importance', key=abs, ascending=False)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Get and display feature importance\n",
    "importance_df = get_feature_importance(pipe, X_train)\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df.head(20))\n",
    "plt.title('Top 20 Most Important Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/feature_importance.png')\n",
    "plt.close()\n",
    "\n",
    "# Residual Analysis\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/residual_plot.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f716b3eb",
   "metadata": {},
   "source": [
    "7. Model Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "611ae53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation R2 Scores: [0.38436886 0.75135427 0.57419953 0.68409945 0.52757092]\n",
      "Mean R2: 0.5843 (±0.1274)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(pipe, X, y, cv=5, scoring='r2')\n",
    "print(\"\\nCross-Validation R2 Scores:\", cv_scores)\n",
    "print(f\"Mean R2: {np.mean(cv_scores):.4f} (±{np.std(cv_scores):.4f})\")\n",
    "\n",
    "# Learning Curve (New)\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    pipe, X, y, cv=5, scoring='r2', \n",
    "    train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Training score')\n",
    "plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Cross-validation score')\n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('R2 Score')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/learning_curve.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8386c53",
   "metadata": {},
   "source": [
    "8. Model Deployment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7662b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Predictions:\n",
      "['Maruti Suzuki Swift', 'Maruti', 2019, 100, 'Petrol'] → Predicted Price: ₹456,670.33\n",
      "['Hyundai Creta', 'Hyundai', 2020, 5000, 'Diesel'] → Predicted Price: ₹678,732.56\n"
     ]
    }
   ],
   "source": [
    "# Create example predictions with proper DataFrame construction\n",
    "examples = [\n",
    "    {'name': 'Maruti Suzuki Swift', 'company': 'Maruti', 'year': 2019, 'kms_driven': 100, 'fuel_type': 'Petrol'},\n",
    "    {'name': 'Hyundai Creta', 'company': 'Hyundai', 'year': 2020, 'kms_driven': 5000, 'fuel_type': 'Diesel'},\n",
    "\n",
    "]\n",
    "\n",
    "print(\"\\nExample Predictions:\")\n",
    "for example in examples:\n",
    "    # Create DataFrame maintaining original column order\n",
    "    input_df = pd.DataFrame([example], columns=X.columns)\n",
    "    \n",
    "    # Predict\n",
    "    try:\n",
    "        pred = pipe.predict(input_df)\n",
    "        print(f\"{list(example.values())} → Predicted Price: ₹{pred[0]:,.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction failed for {example}: {str(e)}\")\n",
    "\n",
    "\n",
    "import json\n",
    "# Save model metadata\n",
    "model_metadata = {\n",
    "    'features': list(X.columns),\n",
    "    'target': 'Price',\n",
    "    'metrics': {\n",
    "        'r2_score': r2,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse\n",
    "    },\n",
    "    'cv_scores': {\n",
    "        'mean': np.mean(cv_scores),\n",
    "        'std': np.std(cv_scores)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to model folder\n",
    "with open('models/model_metadata.json', 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
